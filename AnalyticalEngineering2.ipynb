{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Topological Features of Embedding Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _collections_abc import Iterable\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "\n",
    "import gudhi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_filename(filename:str) -> tuple[str, list[tuple[str]]]:\n",
    "    '''\n",
    "    Parse JSON filesnames produced by CodeEmbeddingsGenerator.py\n",
    "    into the classes, methods, and tokens they are located in.\n",
    "\n",
    "    Args:\n",
    "        filename: JSON filename to parse.\n",
    "    \n",
    "    Returns:\n",
    "        level: Coding level of granularity (i.e., \"class\", \"method\", \"token\")\n",
    "        identifiers: An ordered list of the nested classes, methods, and/or token.\n",
    "    '''\n",
    "    f = filename[:-5]\n",
    "    nesting = []\n",
    "    for m in re.finditer(r'(^|_)(c\\.|m\\.|token)', f):\n",
    "        if (m.group() == 'c.') or (m.group() == '_c.'): level = 'class'\n",
    "        elif (m.group() == 'm.') or (m.group() == '_m.'): level = 'method'\n",
    "        elif (m.group() == 'token') or (m.group() == '_token'): level = 'token'\n",
    "        else:\n",
    "            print(f'Something has gone wrong! \\n\\tFilename: {filename}\\n\\tMatch: {m}')\n",
    "            level = ''\n",
    "\n",
    "        nesting.append((m.start(), m.end(), level))\n",
    "\n",
    "    identifiers = []\n",
    "    for i in range(1, len(nesting)):\n",
    "        end = nesting[i]\n",
    "        start = nesting[i-1]\n",
    "\n",
    "        # Get identifier name and duplicate number \n",
    "        # (or just duplicate number if its a token)\n",
    "        name = f[start[1] : end[0]]\n",
    "        identifiers.append((name, start[2])) # Store name and level\n",
    "\n",
    "    # Get last name and level\n",
    "    last = nesting[-1]\n",
    "    name = f[last[1]:] \n",
    "    identifiers.append((name, last[2]))\n",
    "\n",
    "    # Return embedding level and parsing results\n",
    "    return last[2], identifiers\n",
    "\n",
    "\n",
    "def get_embedding_paths(sub_dirs:list[str] = ['data'], \n",
    "                        levels:list[str] = ['class', 'method', 'token'],\n",
    "                        id_nestings:list[tuple[str]] = []\n",
    "                        ) -> tuple[list[str], list[str]]:\n",
    "    '''\n",
    "    Return file paths for JSON files created by CodeEmbeddingsGenerator.py.\n",
    "    Collects all JSON files in a data folder by default.\n",
    "\n",
    "    sub_dirs: Paths to subdirectories within the data folder to collect the JSON files from.\n",
    "    levels: Embedding levels to collect (i.e., \"class\", \"method\", \"token\").\n",
    "    id_nestings: Ordered lists of classes and/or methods that the code fragments associated with \n",
    "        the embeddings must be found in. The format must match that of the the 2nd output of \n",
    "        parse_json_filename().\n",
    "\n",
    "    Returns:\n",
    "        embed_paths: Paths to the JSON files.\n",
    "        embed_levels: Embedding levels associated with each path in embed_paths.\n",
    "    '''\n",
    "    for level in levels:\n",
    "        if level not in ('class', 'method', 'token'):\n",
    "            print(f'Warning: Invalid level name \"{level}\".')\n",
    "            \n",
    "    embed_paths = []\n",
    "    embed_levels = []\n",
    "    for dir in sub_dirs:\n",
    "        # Search through all JSON files\n",
    "        for path in glob.glob(dir + '/**/*.json', recursive=True):\n",
    "            filename = re.split(r'\\\\|/', path)[-1] # Get filename (and file extension)\n",
    "            level, identifiers = parse_json_filename(filename) # Get embedding level and the nesting\n",
    "            # Collect paths to embeddings of specified levels\n",
    "            if level in levels:\n",
    "                if len(id_nestings) == 0:\n",
    "                    embed_paths.append(path)\n",
    "                    embed_levels.append(level)\n",
    "                    continue\n",
    "                # Collect paths to embeddings that are nested in the specified classes and/or methods\n",
    "                for nesting in id_nestings:\n",
    "                    if nesting == identifiers[:len(nesting)]:\n",
    "                        embed_paths.append(path)\n",
    "                        embed_levels.append(level)\n",
    "                        break\n",
    "    return embed_paths, embed_levels\n",
    "\n",
    "\n",
    "def paths_to_data(paths:Iterable[str]) -> dict:\n",
    "    '''\n",
    "    Takes a list of directory paths to JSON files generated by CodeEmbeddingsGenerator.py, \n",
    "    then loads the data and compiles them into a single dictionary.\n",
    "\n",
    "    Args:\n",
    "        paths: The list of directory paths to JSON files.\n",
    "\n",
    "    Returns:\n",
    "        data: A dataset of embeddings, the associated identifier/token name, \n",
    "            the start and end indices for parsing the original code fragment,\n",
    "            and the directory path to the JSON file.\n",
    "    '''\n",
    "    data = {'embeds':list(), 'names':list(), 'spans':list(), 'paths':list()}\n",
    "    for path in paths:\n",
    "        file = json.load(open(path, 'r'))\n",
    "        data['embeds'].append(file[0][0]) # Embedding\n",
    "        data['names'].append(file[1]) # Identifier or token name\n",
    "        data['spans'].append(file[2]) # Start and end indices in source code\n",
    "        data['paths'].append(path) # Path to file\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods in Each Java File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths, levels = get_embedding_paths(sub_dirs=[dir], levels=['method'])\n",
    "# data = paths_to_data(paths)\n",
    "# data['levels'] = levels\n",
    "\n",
    "# rips = gudhi.RipsComplex(points=data['embeds'])\n",
    "# tree = rips.create_simplex_tree(max_dimension=3)\n",
    "\n",
    "# tree.persistence()\n",
    "# tree.betti_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of all directories to folders of JSON files\n",
    "java_files = list(set(['\\\\'.join(dir.split('\\\\')[:-1]) for dir in glob.glob(\"data\\\\**\\\\*.json\", recursive=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "betti_nums = {}\n",
    "for dir in java_files:\n",
    "    print(f'Working on {dir}')\n",
    "    paths, levels = get_embedding_paths(sub_dirs=[dir], levels=['method'])\n",
    "    data = paths_to_data(paths)\n",
    "    data['levels'] = levels\n",
    "\n",
    "    tree = gudhi.RipsComplex(points=data['embeds']).create_simplex_tree(max_dimension=3)\n",
    "    tree.persistence()\n",
    "    betti_nums[dir] = tree.betti_numbers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ant-ivy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
